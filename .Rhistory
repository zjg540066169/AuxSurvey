}
}
else{
if(!is.na(outcome_formula[2])){
bayesmod <- get(BayesFun)(fmla, family = family, data = svysmpl, iter = nskip + npost, warmup = nskip, weights = weights, chains = nchain, random = as.formula(outcome_formula[2]), refresh = stan_verbose)
}else{
bayesmod <- get(BayesFun)(fmla, family = family, data = svysmpl, iter = nskip + npost, warmup = nskip, weights = weights, chains = nchain, refresh = stan_verbose)
}
#bayesmod <- get(BayesFun)(fmla, data = svysmpl, iter = nskip + npost, warmup = nskip, weights = weights, chains = nchain, random = as.formula(formula[2]))
}
#print("end fit model")
#if (meth %in% c('Cov', 'catCov') )  bayesmod <- stan_glm(fmla, data = svysmpl)
#if (meth %in% c('GAMcatCov' , 'GAM-Cov', 'GAM-PS', 'GAM-lgtPS', 'GAM-slgtPS') ) bayesmod <- stan_gamm4(fmla, data = svysmpl)
#bayesmod <- update(bayesmod, iter = 500)
if (printmod) summary(bayesmod) %>% print()
if (doFigure) {
p1 <- pp_check(bayesmod)
p2 <- pp_check(bayesmod, plotfun = 'scatter_avg')
p3 <- pp_check(bayesmod, plotfun = 'stat_2d', stat = c('mean', 'sd'))
p4 <- pp_check(bayesmod, plotfun = "error_binned")
ppcFig <- gridExtra::grid.arrange(p1, p2, p3, ncol = 3)
ppcFig <- gridExtra::grid.arrange(ppcFig, p4, ncol = 1)
ppcFig
}
if(useTrueSample == F){
infr = sapply(subset, function(s){
#print(s)
svypopu1 = dplyr::filter(svypopu, eval(parse(text = s)))
yhats <- posterior_epred(bayesmod, svypopu1)
post_est = rowMeans(yhats)
tCI = sapply(invlvls, function(level){
if(shortest_CI){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, probs = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(dplyr::filter(svysmpl, eval(parse(text = s)))), population_size = nrow(svypopu1)))
}, simplify = F)
names(infr)[1] = "All"
return(infr)
}else{
infr = sapply(subset, function(s){
svypopu1 = dplyr::filter(svypopu, eval(parse(text = s)))
svysmpl1 = dplyr::filter(svysmpl, eval(parse(text = s)))
yhats_pop <- posterior_predict(bayesmod, svypopu1, re.form = NA) # npost, non-sample_size
yhats_sam <- posterior_predict(bayesmod, svysmpl1, re.form = NA)
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yobs_tot <- sum(svysmpl1 %>% dplyr::select(stringr::str_trim(stringr::str_split_1(outcome_formula[1], "~")[1]))) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
tCI = sapply(invlvls, function(level){
#confint(post_est, level = 0.95)
if(shortest_CI){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
return(infr)
}, simplify = F)
names(infr)[1] = "All"
return(infr)
}
}
MRP_est = svyBayesmod(samples, population, outcome_formula, "stan_glmer", subset, family, levels, weights, nskip, npost, nchain, printmod = TRUE, doFigure = show_plot, useTrueSample = F, stan_verbose = stan_verbose, shortest_CI = HPD_interval)
library(mgcv)
library(rstanarm)
library(dplyr)
#' @param shortest_CI  A logical scalar; if true, the calculated credible intervals for stan models are highest posterior density intervals. Otherwise the intervals are symmetric. Default is false.
#' @return A list. Each element contains the Bayesian estimate and CIs for a subset or the whole data analysis.
#'
#' @import stats
#' @import rstanarm
#' @import survey
#' @import mgcv
#' @import dplyr
#' @import stringr
#'
svyBayesmod <- function(svysmpl, svypopu, outcome_formula, BayesFun, subset = NULL, family = gaussian(), invlvls, weights = NULL, nskip = 1000, npost = 1000, nchain = 4, printmod = TRUE, doFigure = FALSE, useTrueSample = F, stan_verbose = F, shortest_CI = F) {
#print(outcome_formula)
subset = c("T", subset)
fmla <- outcome_formula[1] %>% as.formula()
#print("start fit model")
if(is.null(weights)){
if(!is.na(outcome_formula[2])){
bayesmod <- get(BayesFun)(fmla, family = family, random = as.formula(outcome_formula[2]), data = svysmpl, iter = nskip + npost, warmup = nskip, chains = nchain, refresh = stan_verbose)
}else{
bayesmod <- get(BayesFun)(fmla, family = family, data = svysmpl, iter = nskip + npost, warmup = nskip, chains = nchain, refresh = stan_verbose)
}
}
else{
if(!is.na(outcome_formula[2])){
bayesmod <- get(BayesFun)(fmla, family = family, data = svysmpl, iter = nskip + npost, warmup = nskip, weights = weights, chains = nchain, random = as.formula(outcome_formula[2]), refresh = stan_verbose)
}else{
bayesmod <- get(BayesFun)(fmla, family = family, data = svysmpl, iter = nskip + npost, warmup = nskip, weights = weights, chains = nchain, refresh = stan_verbose)
}
#bayesmod <- get(BayesFun)(fmla, data = svysmpl, iter = nskip + npost, warmup = nskip, weights = weights, chains = nchain, random = as.formula(formula[2]))
}
#print("end fit model")
#if (meth %in% c('Cov', 'catCov') )  bayesmod <- stan_glm(fmla, data = svysmpl)
#if (meth %in% c('GAMcatCov' , 'GAM-Cov', 'GAM-PS', 'GAM-lgtPS', 'GAM-slgtPS') ) bayesmod <- stan_gamm4(fmla, data = svysmpl)
#bayesmod <- update(bayesmod, iter = 500)
if (printmod) summary(bayesmod) %>% print()
if (doFigure) {
p1 <- pp_check(bayesmod)
p2 <- pp_check(bayesmod, plotfun = 'scatter_avg')
p3 <- pp_check(bayesmod, plotfun = 'stat_2d', stat = c('mean', 'sd'))
p4 <- pp_check(bayesmod, plotfun = "error_binned")
ppcFig <- gridExtra::grid.arrange(p1, p2, p3, ncol = 3)
ppcFig <- gridExtra::grid.arrange(ppcFig, p4, ncol = 1)
ppcFig
}
if(useTrueSample == F){
infr = sapply(subset, function(s){
#print(s)
svypopu1 = dplyr::filter(svypopu, eval(parse(text = s)))
yhats <- posterior_epred(bayesmod, svypopu1)
post_est = rowMeans(yhats)
tCI = sapply(invlvls, function(level){
if(shortest_CI){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, probs = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(dplyr::filter(svysmpl, eval(parse(text = s)))), population_size = nrow(svypopu1)))
}, simplify = F)
names(infr)[1] = "All"
return(infr)
}else{
infr = sapply(subset, function(s){
svypopu1 = dplyr::filter(svypopu, eval(parse(text = s)))
svysmpl1 = dplyr::filter(svysmpl, eval(parse(text = s)))
yhats_pop <- posterior_predict(bayesmod, svypopu1, re.form = NA) # npost, non-sample_size
yhats_sam <- posterior_predict(bayesmod, svysmpl1, re.form = NA)
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yobs_tot <- sum(svysmpl1 %>% dplyr::select(stringr::str_trim(stringr::str_split_1(outcome_formula[1], "~")[1]))) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
tCI = sapply(invlvls, function(level){
#confint(post_est, level = 0.95)
if(shortest_CI){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
return(infr)
}, simplify = F)
names(infr)[1] = "All"
return(infr)
}
}
MRP_est = svyBayesmod(samples, population, outcome_formula, "stan_glmer", subset, family, levels, weights, nskip, npost, nchain, printmod = TRUE, doFigure = show_plot, useTrueSample = F, stan_verbose = stan_verbose, shortest_CI = HPD_interval)
family = gaussian()
levels = 0.95
weights = NULL
show_plot
show_plot = F
useTrueSample = F
stan_verbose = T
HPD_interval = T
MRP_est = svyBayesmod(samples, population, outcome_formula, "stan_glmer", subset, family, levels, weights, nskip, npost, nchain, printmod = TRUE, doFigure = show_plot, useTrueSample = F, stan_verbose = stan_verbose, shortest_CI = HPD_interval)
svysmpl = samples
svypopu = population
outcome_formula
BayesFun = "stan_glmer"
subset = NULL
family = gaussian()
invlvls = 0.95
weights = NULL
#print(outcome_formula)
subset = c("T", subset)
fmla <- outcome_formula[1] %>% as.formula()
#print("start fit model")
if(is.null(weights)){
if(!is.na(outcome_formula[2])){
bayesmod <- get(BayesFun)(fmla, family = family, random = as.formula(outcome_formula[2]), data = svysmpl, iter = nskip + npost, warmup = nskip, chains = nchain, refresh = stan_verbose)
}else{
bayesmod <- get(BayesFun)(fmla, family = family, data = svysmpl, iter = nskip + npost, warmup = nskip, chains = nchain, refresh = stan_verbose)
}
}
summary(bayesmod) %>% print()
p1 <- pp_check(bayesmod)
p2 <- pp_check(bayesmod, plotfun = 'scatter_avg')
p3 <- pp_check(bayesmod, plotfun = 'stat_2d', stat = c('mean', 'sd'))
p4 <- pp_check(bayesmod, plotfun = "error_binned")
ppcFig <- gridExtra::grid.arrange(p1, p2, p3, ncol = 3)
ppcFig <- gridExtra::grid.arrange(ppcFig, p4, ncol = 1)
ppcFig
useTrueSample
s = subset[1]
s
#print(s)
svypopu1 = dplyr::filter(svypopu, eval(parse(text = s)))
yhats <- posterior_epred(bayesmod, svypopu1)
remove.packages("Matrix")
remove.packages("lme4")
install.packages("lme4", type = "source")
library(lme4)
install.packages("lme4", type = "source")
posterior_epred
library(rstanarm)
yhats <- posterior_epred(bayesmod, svypopu1)
nstall.packages("lme4", type = "source")
install.packages("lme4", type = "source")
install.packages("lme4", type = "source")
install.packages("lme4", type = "source")
install.packages("lme4", type = "source")
library(lme4)
MRP_est = svyBayesmod(samples, population, outcome_formula, "stan_glmer", subset, family, levels, weights, nskip, npost, nchain, printmod = TRUE, doFigure = show_plot, useTrueSample = F, stan_verbose = stan_verbose, shortest_CI = HPD_interval)
library(AuxSurvey)
auxsurvey("Y1 ~ Z1 + Z2 + Z3", auxiliary = "auX_10", samples = data$samples, population = data$population, method = "MRP")
auxsurvey("Y1 ~ Z1 + Z2 + Z3 + auX_10", auxiliary = NULL, samples = data$samples, population = data$population, method = "BART")
auxsurvey("Y1 ~ Z1 + Z2 + Z3", auxiliary = "s(logit_true_pi) + s(auX_10)", samples = data$samples, population = data$population, method = "GAMP")
?BART::wbart
library(AuxSurvey)
library(AuxSurvey)
devtools::check()
devtools::check()
devtools::check()
devtools::check()
library(AuxSurvey)
library(AuxSurvey)
data = simulate(N = 3000, discretize = c(3, 5, 10), setting = 1, seed = 123) # setting parameter takes values in {1,2,3}, which corresponds the three simulation scenarios in paper.
population = data$population # get population, 3000 cases
samples = data$samples # get samples, about 600 cases
ipw = 1 / samples$true_pi # get the true inverse probability weighting in sample
est_ipw = 1 / samples$estimated_pi # get the estimated inverse probability weighting in sample
true_mean = mean(population$Y1) # true value of the estimator
# Unweighted sample mean
# subset: the whole data.
sample_mean = auxsurvey("~Y1",  auxiliary = NULL, weights = NULL, samples = samples, population = NULL, subset = NULL, method = "sample_mean", levels = 0.95)
# IPW sample mean
# subset: the whole data and subset of Z1 == 1 & Z2 == 1.
# CIs are calculated with finite population correction
IPW_sample_mean = auxsurvey("~Y1",  auxiliary = NULL, weights = ipw, samples = samples, population = population, subset = c("Z1 == 1 & Z2 == 1"), method = "sample_mean", levels = 0.95)
# Estimated IPW sample mean of binary outcome
# subset: the whole data and subsets of Z1 == 1 and Z1 == 1 & Z2 == 1.
Est_IPW_sample_mean = auxsurvey("~Y2",  auxiliary = NULL, weights = est_ipw, samples = samples, population = NULL, subset = c("Z1 == 1", "Z1 == 1 & Z2 == 1"), family = binomial(), method = "sample_mean", levels = 0.95)
sample_mean
IPW_sample_mean
Est_IPW_sample_mean
# Unweighted Raking for auX_5, with interaction with Z1
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
rake_5_Z1 = auxsurvey("~Y1",  auxiliary = "Z2 + Z3 + auX_5 * Z1", weights = NULL, samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "rake", levels = 0.95)
# IPW Raking for auX_10
# subset: the whole data and subsets of Z1 == 1 and Z1 == 1 & Z2 == 1.
# CIs: 0.95, 0.8
rake_10 = auxsurvey("~Y1",  auxiliary = "Z1 + Z2 + Z3 + auX_10", weights = ipw, samples = samples, population = population, subset = c("Z1 == 1", "Z1 == 1 & Z2 == 1"), method = "rake", levels = c(0.95, 0.8))
# Estimated IPW Raking for auX_3, binary outcome
# subset: the whole data.
rake_3 = auxsurvey("~Y2",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = est_ipw, samples = samples, population = population, subset = NULL, family = binomial(), method = "rake", levels = 0.95)
# Unweighted Poststratification for auX_3
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
ps_3 = auxsurvey("~Y1",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = NULL, samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "postStratify", levels = 0.95)
# IPW Poststratification for auX_3, binary outcome
# subset: the whole data and subsets of Z1 == 1 and Z1 == 1 & Z2 == 1.
# CIs: 0.95, 0.8
ps_3_binary = auxsurvey("~Y2",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = ipw, samples = samples, population = population, subset = c("Z1 == 1", "Z1 == 1 & Z2 == 1"), family = binomial(), method = "postStratify", levels = c(0.95, 0.8))
ps_3 = auxsurvey("~Y1",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = NULL, samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "postStratify", levels = 0.95)
library(AuxSurvey)
library(AuxSurvey)
library(AuxSurvey)
data = simulate(N = 3000, discretize = c(3, 5, 10), setting = 1, seed = 123) # setting parameter takes values in {1,2,3}, which corresponds the three simulation scenarios in paper.
population = data$population # get population, 3000 cases
samples = data$samples # get samples, about 600 cases
ipw = 1 / samples$true_pi # get the true inverse probability weighting in sample
est_ipw = 1 / samples$estimated_pi # get the estimated inverse probability weighting in sample
true_mean = mean(population$Y1) # true value of the estimator
# Unweighted Poststratification for auX_3
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
ps_3 = auxsurvey("~Y1",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = NULL, samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "postStratify", levels = 0.95)
# IPW Poststratification for auX_3, binary outcome
# subset: the whole data and subsets of Z1 == 1 and Z1 == 1 & Z2 == 1.
# CIs: 0.95, 0.8
ps_3_binary = auxsurvey("~Y2",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = ipw, samples = samples, population = population, subset = c("Z1 == 1", "Z1 == 1 & Z2 == 1"), family = binomial(), method = "postStratify", levels = c(0.95, 0.8))
library(AuxSurvey)
library(AuxSurvey)
# Unweighted Poststratification for auX_3
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
ps_3 = auxsurvey("~Y1",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = NULL, samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "postStratify", levels = 0.95)
# IPW Poststratification for auX_3, binary outcome
# subset: the whole data and subsets of Z1 == 1 and Z1 == 1 & Z2 == 1.
# CIs: 0.95, 0.8
ps_3_binary = auxsurvey("~Y2",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = ipw, samples = samples, population = population, subset = c("Z1 == 1", "Z1 == 1 & Z2 == 1"), family = binomial(), method = "postStratify", levels = c(0.95, 0.8))
ps_3_binary = auxsurvey("~Y2",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = ipw, samples = samples, population = population, subset = c("Z1 == 1", "Z1 == 1 & Z2 == 1"), family = binomial(), method = "postStratify", levels = c(0.95, 0.8))
# Unweighted Poststratification for auX_3
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
ps_3 = auxsurvey("~Y1",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = NULL, samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "postStratify", levels = 0.95)
library(AuxSurvey)
library(AuxSurvey)
library(AuxSurvey)
data = simulate(N = 3000, discretize = c(3, 5, 10), setting = 1, seed = 123) # setting parameter takes values in {1,2,3}, which corresponds the three simulation scenarios in paper.
population = data$population # get population, 3000 cases
samples = data$samples # get samples, about 600 cases
ipw = 1 / samples$true_pi # get the true inverse probability weighting in sample
est_ipw = 1 / samples$estimated_pi # get the estimated inverse probability weighting in sample
true_mean = mean(population$Y1) # true value of the estimator
# Unweighted sample mean
# subset: the whole data.
sample_mean = auxsurvey("~Y1",  auxiliary = NULL, weights = NULL, samples = samples, population = NULL, subset = NULL, method = "sample_mean", levels = 0.95)
# IPW sample mean
# subset: the whole data and subset of Z1 == 1 & Z2 == 1.
# CIs are calculated with finite population correction
IPW_sample_mean = auxsurvey("~Y1",  auxiliary = NULL, weights = ipw, samples = samples, population = population, subset = c("Z1 == 1 & Z2 == 1"), method = "sample_mean", levels = 0.95)
# Estimated IPW sample mean of binary outcome
# subset: the whole data and subsets of Z1 == 1 and Z1 == 1 & Z2 == 1.
Est_IPW_sample_mean = auxsurvey("~Y2",  auxiliary = NULL, weights = est_ipw, samples = samples, population = NULL, subset = c("Z1 == 1", "Z1 == 1 & Z2 == 1"), family = binomial(), method = "sample_mean", levels = 0.95)
# Unweighted Raking for auX_5, with interaction with Z1
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
rake_5_Z1 = auxsurvey("~Y1",  auxiliary = "Z2 + Z3 + auX_5 * Z1", weights = NULL, samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "rake", levels = 0.95)
# IPW Raking for auX_10
# subset: the whole data and subsets of Z1 == 1 and Z1 == 1 & Z2 == 1.
# CIs: 0.95, 0.8
rake_10 = auxsurvey("~Y1",  auxiliary = "Z1 + Z2 + Z3 + auX_10", weights = ipw, samples = samples, population = population, subset = c("Z1 == 1", "Z1 == 1 & Z2 == 1"), method = "rake", levels = c(0.95, 0.8))
# Estimated IPW Raking for auX_3, binary outcome
# subset: the whole data.
rake_3 = auxsurvey("~Y2",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = est_ipw, samples = samples, population = population, subset = NULL, family = binomial(), method = "rake", levels = 0.95)
# Unweighted Poststratification for auX_3
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
ps_3 = auxsurvey("~Y1",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = NULL, samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "postStratify", levels = 0.95)
# IPW Poststratification for auX_3, binary outcome
# subset: the whole data and subsets of Z1 == 1 and Z1 == 1 & Z2 == 1.
# CIs: 0.95, 0.8
ps_3_binary = auxsurvey("~Y2",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = ipw, samples = samples, population = population, subset = c("Z1 == 1", "Z1 == 1 & Z2 == 1"), family = binomial(), method = "postStratify", levels = c(0.95, 0.8))
# MRP with auX_3
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
# The model is Y1 ~ 1 + Z1 + Z2 + (1|Z3) + (1|auX_3)
MRP_1 = auxsurvey("Y1~1 + Z1 + Z2",  auxiliary = "Z3 + auX_3", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "MRP", levels = 0.95)
# MRP with auX_10, nested within Z1
# subset: the whole data.
# The model is Y1 ~ 1 + Z1 + Z2 + Z3 + (1|Z1:auX_3)
MRP_2 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "Z1:auX_3", samples = samples, population = population, subset = NULL, method = "MRP", levels = 0.95)
# MRP with auX_10, nested within Z1. Z3 will be used in both fixed and random parts. Outcome is binary.
# subset: the whole data.
# CI are HPD_interval
# The model is Y2 ~ 1 + Z1 + Z2 + Z3 + (1|auX_3) + (1|Z3).
MRP_3 = auxsurvey("Y2~1 + Z1 + Z2 + Z3",  auxiliary = "Z3 + auX_3", samples = samples, population = population, subset = NULL, family = binomial(), method = "MRP", levels = 0.95, HPD_interval = T)
MRP_1
MRP_2
MRP_3
GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi) + s(auX_3)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi, 2) + s(auX_3, 2)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
GAMP_2 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi, by = Z1) + s(auX_3, by = Z1)", samples = samples, population = population, subset = NULL, method = "GAMP", levels = 0.95)
GAMP_2 = auxsurvey("Y1~1 + Z1",  auxiliary = "s(logit_estimated_pi, by = Z1) + s(auX_3, by = Z1)", samples = samples, population = population, subset = NULL, method = "GAMP", levels = 0.95)
GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = " s(auX_3, 2)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
LR_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "auX_3", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "linear", levels = 0.95,  HPD_interval = T)
LR_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "auX_3", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "linear", family = gaussian(), levels = 0.95,  HPD_interval = T)
LR_2 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "auX_5 + I(auX_5^2)", samples = samples, population = population, subset = NULL, method = "linear", levels = 0.95)
LR_2 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "auX_5 + I(auX_5^2)", samples = samples, population = population, subset = NULL, method = "linear", levels = 0.95)
?s
View(IPW_sample_mean)
# BART
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
# CI are HPD_interval
BART_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3 + auX_3",  auxiliary = NULL, samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "BART", levels = 0.95,  HPD_interval = T)
# BART
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
# CI are HPD_interval
BART_1 = auxsurvey("Y1~Z1 + Z2 + Z3 + auX_3",  auxiliary = NULL, samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "BART", levels = 0.95,  HPD_interval = T)
# BART
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
# CI are HPD_interval
BART_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3 + auX_3",  auxiliary = NULL, samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "BART", levels = 0.95,  HPD_interval = T)
# BART
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
# CI are HPD_interval
BART_1 = auxsurvey("Y1~ Z1 + Z2 + Z3 + auX_3",  auxiliary = NULL, samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "BART", levels = 0.95,  HPD_interval = T)
BART_1
data$population[, "Y1"]
mean(data$population[, "Y1"])
mean(unlist(data$population[, "Y1"]))
BART_1
# BART
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
# CI are HPD_interval
BART_1 = auxsurvey("Y1~ Z1 + Z2 + Z3 + auX_3 + logit_true_pi",  auxiliary = NULL, samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "BART", levels = 0.95,  HPD_interval = T)
BART_1
GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi) + s(auX_3)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi, 2)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
formula = "Y1~1 + Z1 + Z2 + Z3"
auxiliary = "s(logit_estimated_pi, 2)"
#print(s)
# get estmates and standard error
infr <- cbind(est = PSest[svyVar], se = sqrt(diag(vcov(PSest))), tCI, sample_size = survey::degf(PSobj) + 1, population_size = nrow(dplyr::filter(svypopu, eval(parse(text = s)))))
samples
family = gaussian()
weights = NULL
levels = c(0.95, 0.8, 0.5)
stan_verbose = TRUE
show_plot = TRUE
nskip = 1000
npost = 1000
nchain = 2
HPD_interval
HPD_interval = T
svyVar = stringr::str_trim(stringr::str_split_1(as.character(formula), "~"))
svyVar = svyVar[svyVar != ""][1]
if(!is.null(auxiliary)){
auxiliary = as.character(auxiliary)
auxiliary = stringr::str_remove_all(auxiliary, " ")
auxiliary = paste0(auxiliary, collapse = "+")
if(!stringr::str_detect(auxiliary, "^~")){
auxiliary = paste0("~",auxiliary)
}
}
if(!is.null(population)){
if(length(setdiff(union(all.vars(as.formula(auxiliary)), all.vars(as.formula(formula))), union(svyVar, colnames(population)))) > 0){
stop(paste0("unidentified variables: ", paste0(setdiff(union(all.vars(as.formula(auxiliary)), all.vars(as.formula(formula))), colnames(population)), collapse = ", "), collapse = ", "))
}
}
if(length(setdiff(union(all.vars(as.formula(auxiliary)), all.vars(as.formula(formula))), colnames(samples))) > 0){
stop(paste0("unidentified variables: ", paste0(setdiff(union(all.vars(as.formula(auxiliary)), all.vars(as.formula(formula))), colnames(samples)), collapse = ", "), collapse = ", "))
}
#samples_matrix = model.matrix(as.formula(paste(paste0("~", str_split_i(formula, "~", 2)), paste0(auxiliary, collapse = "+"), sep = "+")), data = samples)
samples = dplyr::mutate_at(samples, all.vars(as.formula(auxiliary)), as.numeric)
population = dplyr::mutate_at(population, intersect(all.vars(as.formula(auxiliary)), colnames(population)), as.numeric)
auxiliary = stringr::str_replace_all(auxiliary, "\\*", ":")
auxiliary_fixed = setdiff(stringr::str_split(stringr::str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T), all.vars(as.formula(auxiliary)))[stringr::str_detect(stringr::str_split(stringr::str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T), "s\\(.*\\)")]
outcome_formula = paste(formula, paste(auxiliary_fixed, collapse = "+"), sep = "+")
auxiliary_random = union(intersect(stringr::str_split(stringr::str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T), all.vars(as.formula(auxiliary))), stringr::str_split(stringr::str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T)[is.na(stringr::str_match(stringr::str_split(stringr::str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T), "s\\(.*\\)"))])
if(length(auxiliary_random) > 0){
samples = dplyr::mutate_at(samples, all.vars(as.formula(paste0("~", auxiliary_random))), as.factor)
population = dplyr::mutate_at(population, all.vars(as.formula(paste0("~", auxiliary_random))), as.factor)
}
if(length(auxiliary_random) != 0){
outcome_formula = c(outcome_formula, paste0("~", paste0("(1|", auxiliary_random, ")", collapse = "+")))
cat("The formula for the GAMP model is ", paste0(outcome_formula[1], str_replace(outcome_formula[2], "~", "+"), collapse = ""), "\n")
}else{
outcome_formula = c(outcome_formula, NULL)
cat("The formula for the GAMP model is ", outcome_formula[1], "\n")
}
GAMP_est = svyBayesmod(samples, population, outcome_formula, "stan_gamm4", subset, family, levels, weights, nskip, npost, nchain, printmod = T, doFigure = F, useTrueSample = T, stan_verbose = stan_verbose, shortest_CI = HPD_interval)
GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi, 2)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
samples$logit_estimated_pi
GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi, 2)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
stan_gamm4(Y1~1 + Z1 + Z2 + Z3+s(logit_estimated_pi,2), family = gaussian(), data = samples, iter = 2000, warmup = 1000 )
stan_gamm4(Y1~1 + Z1 + Z2 + Z3+ mgcv::s(logit_estimated_pi,2), family = gaussian(), data = samples, iter = 2000, warmup = 1000 )
stan_gamm4(Y1~1 + Z1 + Z2 + Z3+ mgcv::s(logit_estimated_pi), family = gaussian(), data = samples, iter = 2000, warmup = 1000 )
?s
??s
?lme4::s
stan_gamm4(Y1~1 + Z1 + Z2 + Z3+ s(logit_estimated_pi), family = gaussian(), data = samples, iter = 2000, warmup = 1000 )
GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
library(AuxSurvey)
library(AuxSurvey)
data = simulate(N = 3000, discretize = c(3, 5, 10), setting = 1, seed = 123) # setting parameter takes values in {1,2,3}, which corresponds the three simulation scenarios in paper.
population = data$population # get population, 3000 cases
samples = data$samples # get samples, about 600 cases
ipw = 1 / samples$true_pi # get the true inverse probability weighting in sample
est_ipw = 1 / samples$estimated_pi # get the estimated inverse probability weighting in sample
true_mean = mean(population$Y1) # true value of the estimator
# GAMP with smooth functions on auX_3 and logit_estimated_pi
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
# The model is Y1 ~ 1 + Z1 + Z2 + Z3 + s(logit_estimated_pi) + s(auX_3)
GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi) + s(auX_3)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
# This is equivalent to
# GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3 + s(logit_estimated_pi)",  auxiliary = "s(auX_3)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi) + s(auX_3)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi) + s(auX_10)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
# GAMP with smooth functions on auX_10 and logit_estimated_pi
# subset: the whole data and subset of Z1 == 1 & Z2 == 1 & Z3 == 0.
# The model is Y1 ~ 1 + Z1 + Z2 + Z3 + s(logit_estimated_pi) + s(auX_10)
GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi) + s(auX_10)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
# This is equivalent to
# GAMP_1 = auxsurvey("Y1~1 + Z1 + Z2 + Z3 + s(logit_estimated_pi)",  auxiliary = "s(auX_10)", samples = samples, population = population, subset = "Z1 == 1 & Z2 == 1 & Z3 == 0", method = "GAMP", levels = 0.95)
# GAMP with smooth functions on logit_estimated_pi and auX_10 with interaction on Z1
# subset: the whole data.
# The model is Y1 ~ 1 + Z1 + Z2 + Z3 + s(logit_estimated_pi, by = Z1) + s(auX_10, by = Z1)
GAMP_2 = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(logit_estimated_pi, by = Z1) + s(auX_10, by = Z1)", samples = samples, population = population, subset = NULL, method = "GAMP", levels = 0.95)
# GAMP with smooth functions on logit_estimated_pi and auX_10 with interaction on Z1, and Z3 as random effects
# subset: the whole data.
# CI are HPD_interval
# The model is Y1 ~ 1 + Z1 + Z2 + s(logit_estimated_pi, by = Z1) + s(auX_10, by = Z1) + (1|Z3)
GAMP_3 = auxsurvey("Y1~1 + Z1 + Z2",  auxiliary = "s(logit_estimated_pi, by = Z1) + s(auX_10, by = Z1) + Z3", samples = samples, population = population, subset = NULL, method = "GAMP", levels = 0.95, HPD_interval = T)
# GAMP with smooth functions on logit_estimated_pi and auX_10 with interaction on Z1, and Z1:Z3 as random effects. We can specify the number of degrees of smooth function. Outcome is binary.
# subset: the whole data.
# The model is Y2 ~ 1 + Z1 + Z2 + s(logit_estimated_pi, by = Z1, k = 3) + s(auX_10, by = Z1, k = 5) + (1|Z1:Z3)
GAMP_4 = auxsurvey("Y2~1 + Z1 + Z2",  auxiliary = "s(logit_estimated_pi, by = Z1, k = 3) + s(auX_10, by = Z1, k = 2) + Z1:Z3", samples = samples, population = population, subset = NULL, family = binomial(), method = "GAMP", levels = 0.95)
GAMP_1
GAMP_2
GAMP_3
GAMP_4
