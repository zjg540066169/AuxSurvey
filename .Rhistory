#' @param weights A numeric vector of case weights. The length should be equal to the number of cases in 'samples'.
#' @param levels A numeric vector of values. Each specifies a confidence level of CI for estimators. If more than one values are specified, then multiple CIs are calculated.
#' @param stan_verbose A logical scalar; if true, print all messages when running stan models. Default is false. This parameter only works for Bayesian models.
#' @param show_plot A logical scalar; if true, show some diagnostic plots for stan models. Default is false. This parameter only works for Bayesian models.
#' @param nskip A integer to specify the number of burn-in iterations of each chain in MCMC for stan models. Default is 1000. This parameter only works for Bayesian models.
#' @param npost A integer to specify the number of posterior sampling iteration of each chain in MCMC for stan models. Default is 1000. This parameter only works for Bayesian models.
#' @param nchain A integer to specify the number of MCMC chains for stan models. Default is 4. This parameter only works for Bayesian models.
#' @param HPD_interval A logical scalar; if true, the calculated credible intervals for stan models are highest posterior density intervals. Otherwise the intervals are symmetric. Default is false. This parameter only works for Bayesian models.
#'
#' @import stats
#' @import gtools
#' @import rstanarm
#' @import survey
#' @import tidyverse
#' @import mgcv
#' @import dplyr
#' @import stringr
#'
#'
#' @return A list. Each element contains the estimate and CIs for a subset or the whole data analysis.
#' @export
#'
#' @examples
#' \dontrun{
#' ## simulate data from the 'simulate' function, with nonlinear association setting 3.
#' ## The continuous variable X is discretized into categorical variable auX_3 with 3 categories,
#' ## and auX_10 with 10 categories.
#' data = simulate(N = 3000, discretize = c(3, 10), setting = 3, seed = 123)
#'
#' ## The dataset consists of a continuous outcome Y, 3 binary variables Z1, Z2, Z3;
#' ## discretized variables auX_3 and auX_10.
#' ## Propensity scores true_pi and it log transformation logit_true_pi are calculated.
#' population = data$population # get population, 3000 cases
#' samples = data$samples # get samples, about 600 cases
#' ipw = 1 / samples$true_pi # get the inverse probability weighting
#'
#' ## IPW sample mean, with analysis on subset Z1 == 1 & Z2 == 1.
#' IPW_sample_mean = auxsurvey("~Y1",  auxiliary = NULL, weights = ipw,
#'                    samples = samples, population = population,
#'                    subset = c("Z1 == 1 & Z2 == 1"), method = "sample_mean", levels = 0.95)
#'
#' ## rake, with analysis on subsets Z1 == 1 and Z1 == 1 & Z2 == 1.
#' rake = auxsurvey("~Y1",  auxiliary = "Z1 + Z2 + Z3 + auX_10", samples = samples,
#'          population = population, subset = c("Z1 == 1", "Z1 == 1 & Z2 == 1"),
#'          method = "rake", levels = 0.95)
#'
#' ## IPW post-stratification, no subset analysis.
#' IPW_postStratify3 = auxsurvey("~Y1",  auxiliary = "Z1 + Z2 + Z3 + auX_3", weights = ipw,
#'                      samples = samples, population = population,
#'                      method = "postStratify", levels = 0.95)
#'
#' ## MRP, with analysis on subsets Z1 == 1, Z1 == 1 & Z2 == 1, Z1 == 1 & Z2 == 1 & Z3 == 1.
#' MRP = auxsurvey("Y1~1 + Z1",  auxiliary = "Z2 + Z3:auX_10", samples = samples,
#'         population = population,
#'         subset = c("Z1 == 1", "Z1 == 1 & Z2 == 1", "Z1 == 1 & Z2 == 1 & Z3 == 1"),
#'         method = "MRP", levels = 0.95, nskip = 4000, npost = 4000,
#'         nchain = 1, stan_verbose = F, HPD_interval = T)
#'
#' ## GAMP, no subset analysis.
#' GAMP = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(auX_10) + s(logit_true_pi, by = Z1)",
#'           samples = samples, population = population, subset = NULL, method = "GAMP",
#'          levels = 0.95, nskip = 4000, npost = 4000, nchain = 1, stan_verbose = F, HPD_interval = T)
#' }
auxsurvey <- function(formula, auxiliary = NULL, samples, population = NULL, subset = NULL, family = gaussian(), method = c("sample_mean", "rake", "postStratify", "MRP", "GAMP", "linear"), weights = NULL, levels = c(0.95, 0.8, 0.5), stan_verbose = TRUE, show_plot = TRUE, nskip = 1000, npost = 1000, nchain = 4, HPD_interval = FALSE){
svyVar = stringr::str_trim(str_split_1(as.character(formula), "~"))
svyVar = svyVar[svyVar != ""][1]
if(!is.null(auxiliary)){
auxiliary = as.character(auxiliary)
auxiliary = stringr::str_remove_all(auxiliary, " ")
auxiliary = paste0(auxiliary, collapse = "+")
if(!str_detect(auxiliary, "^~")){
auxiliary = paste0("~",auxiliary)
}
}
if(length(setdiff(union(all.vars(as.formula(auxiliary)), all.vars(as.formula(formula))), colnames(population))) > 0){
stop(paste0("unidentified variables: ", paste0(setdiff(union(all.vars(as.formula(auxiliary)), all.vars(as.formula(formula))), colnames(population)), collapse = ", "), collapse = ", "))
}
#auxiliary = str_trim(str_split(auxiliary, "\\+", simplify = T))
#auxiliary = str_remove_all()
method = match.arg(method)
# if(is.null(propensity_score))
#   weights = NULL
# else{
#   weights = 1 / propensity_score
# }
if(method == "sample_mean"){
return(uwt(samples, svyVar, subset, levels, weights))
}
if(method == "rake"){
covariates = stringr::str_trim(stringr::str_split(stringr::str_split_i(as.character(formula), "~", 2), "\\+", simplify = T))
covariates = setdiff(covariates, svyVar)
if("." %in% covariates){
covariates = setdiff(names(samples), svyVar)
}
auxiliary = stringr::str_trim(stringr::str_split(stringr::str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T))
auxiliary = auxiliary[!is.na(auxiliary) & auxiliary != ""]
return(rake_wt(samples, population, auxiliary, svyVar, subset, family = family, levels, weights, maxiter = 50))
}
if(method == "postStratify"){
covariates = stringr::str_trim(stringr::str_split(stringr::str_split_i(as.character(formula), "~", 2), "\\+", simplify = T))
covariates = setdiff(covariates, svyVar)
if("." %in% covariates){
covariates = setdiff(names(samples), svyVar)
}
auxiliary = unique(c(all.vars(as.formula(auxiliary)), covariates))
auxiliary = auxiliary[!is.na(auxiliary) & auxiliary != ""]
return(postStr_wt(samples, population, auxiliary, svyVar, subset, family = family, levels, weights))
}
if(method == "MRP"){
if(is.null(nskip)) nskip = 1000
if(is.null(npost)) npost = 1000
if(is.null(nchain)) nchain = 4
covariates = stringr::str_trim(stringr::str_split(stringr::str_split_i(as.character(formula), "~", 2), "\\+", simplify = T))
covariates = setdiff(covariates, svyVar)
if("." %in% covariates){
covariates = setdiff(names(samples), svyVar)
}
samples = mutate_at(samples, all.vars(as.formula(auxiliary)), as.factor)
population = mutate_at(population, all.vars(as.formula(auxiliary)), as.factor)
auxiliary = stringr::str_replace_all(auxiliary, "\\*", ":")
auxiliary = stringr::str_split_i(as.character(auxiliary), "~", 2)
auxiliary = stringr::str_split(auxiliary, "\\+", simplify = T)
if(length(covariates) == 0){
outcome_formula = paste0(paste0(svyVar, "~"), paste0("(1|", auxiliary, ")", collapse = "+"))
}else{
outcome_formula = paste(paste0(svyVar, "~", paste0(covariates, collapse = "+")), paste0("(1|", auxiliary, ")", collapse = "+"), sep= "+")
}
cat("The formula for the MRP model is ", outcome_formula, "\n")
MRP_est = svyBayesmod(samples, population, outcome_formula, "stan_glmer", subset, family, levels, weights, nskip, npost, nchain, printmod = TRUE, doFigure = show_plot, useTrueSample = F, stan_verbose = stan_verbose, shortest_CI = HPD_interval)
MRP_est =  lapply(MRP_est, function(est){
if(is.null(weights))
rownames(est) = "MRP"
else{
rownames(est) = "Weighted-MRP"
}
return(est)
})
if(length(MRP_est) == 1)
return(MRP_est[[1]])
return(MRP_est)
}
if(method == "GAMP"){
if(is.null(nskip)) nskip = 1000
if(is.null(npost)) npost = 1000
if(is.null(nchain)) nchain = 4
#covariates = str_trim(str_split(str_split_i(as.character(formula), "~", 2), "\\+", simplify = T))
#if("." %in% covariates){
#  covariates = setdiff(names(samples), svyVar)
#}
#samples_matrix = model.matrix(as.formula(paste(paste0("~", str_split_i(formula, "~", 2)), paste0(auxiliary, collapse = "+"), sep = "+")), data = samples)
samples = mutate_at(samples, all.vars(as.formula(auxiliary)), as.numeric)
population = mutate_at(population, intersect(all.vars(as.formula(auxiliary)), colnames(population)), as.numeric)
auxiliary_fixed = setdiff(stringr::str_split(stringr::str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T), all.vars(as.formula(auxiliary)))
outcome_formula = paste(formula, paste(auxiliary_fixed, collapse = "+"), sep = "+")
auxiliary_random = intersect(stringr::str_split(stringr::str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T), all.vars(as.formula(auxiliary)))
samples = mutate_at(samples, auxiliary_random, as.factor)
population = mutate_at(population, auxiliary_random, as.factor)
if(length(auxiliary_random) != 0){
outcome_formula = c(outcome_formula, paste0("~", paste0("(1|", auxiliary_random, ")", collapse = "+")))
cat("The formula for the GAMP model is ", paste0(outcome_formula[1], str_replace(outcome_formula[2], "~", "+"), collapse = ""), "\n")
}else{
outcome_formula = c(outcome_formula, NULL)
cat("The formula for the GAMP model is ", outcome_formula[1], "\n")
}
#outcome_formula = paste(formula, paste0(str_remove_all(auxiliary, "~"), collapse = "+"), paste0("(1|", auxiliary_random, ")", collapse = "+"),  sep = "+")
GAMP_est = svyBayesmod(samples, population, outcome_formula, "stan_gamm4", subset, family, levels, weights, nskip, npost, nchain, printmod = T, doFigure = F, useTrueSample = T, stan_verbose = stan_verbose, shortest_CI = HPD_interval)
GAMP_est =  lapply(GAMP_est, function(est){
if(is.null(weights))
rownames(est) = "GAMP"
else{
rownames(est) = "Weighted-GAMP"
}
return(est)
})
if(length(GAMP_est) == 1)
return(GAMP_est[[1]])
return(GAMP_est)
}
if(method == "linear"){
if(is.null(nskip)) nskip = 1000
if(is.null(npost)) npost = 1000
if(is.null(nchain)) nchain = 4
samples = mutate_at(samples, all.vars(as.formula(auxiliary)), as.numeric)
population = mutate_at(population, intersect(all.vars(as.formula(auxiliary)), colnames(population)), as.numeric)
auxiliary_fixed = setdiff(stringr::str_split(stringr::str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T), all.vars(as.formula(auxiliary)))
outcome_formula = paste(formula, paste(auxiliary_fixed, collapse = "+"), collapse = "+")
auxiliary_random = intersect(str_split(str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T), all.vars(as.formula(auxiliary)))
samples = mutate_at(samples, auxiliary_random, as.factor)
population = mutate_at(population, auxiliary_random, as.factor)
if(length(auxiliary_random) != 0){
outcome_formula = c(outcome_formula, paste0("~", paste0("(1|", auxiliary_random, ")", collapse = "+")))
cat("The formula for the linear model is ", paste0(outcome_formula[1], str_replace(outcome_formula[2], "~", "+"), collapse = ""), "\n")
Linear_est = svyBayesmod(samples, population, outcome_formula, "stan_glmer", family, levels, weights, nskip, npost, nchain, printmod = T, doFigure = F, useTrueSample = T, stan_verbose = stan_verbose, shortest_CI = HPD_interval)
}else{
outcome_formula = c(outcome_formula, NULL)
cat("The formula for the linear model is ", outcome_formula, "\n")
Linear_est = svyBayesmod(samples, population, outcome_formula, "stan_glm", subset, family, levels, weights, nskip, npost, nchain, printmod = T, doFigure = F, useTrueSample = T, stan_verbose = stan_verbose, shortest_CI = HPD_interval)
}
Linear_est = lapply(Linear_est, function(est){
if(is.null(weights))
rownames(est) = "linear"
else{
rownames(est) = "Weighted-linear"
}
return(est)
})
if(length(Linear_est) == 1)
return(Linear_est[[1]])
#outcome_formula = paste(formula, paste0(str_remove_all(auxiliary, "~"), collapse = "+"), paste0("(1|", auxiliary_random, ")", collapse = "+"),  sep = "+")
return(Linear_est)
}
}
data = simulate(N = 3000, discretize = c(3, 10), setting = 3, seed = 123)
population = data$population # get population, 3000 cases
samples = data$samples # get samples, about 600 cases
ipw = 1 / samples$true_pi # get the inverse probability weighting
ipw = 1 / samples$true_pi # get the inverse probability weighting
ipw
GAMP = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(auX_10) + s(logit_true_pi, by = Z1)",
samples = samples, population = population, subset = NULL, method = "GAMP",
levels = 0.95, nskip = 4000, npost = 4000, nchain = 1, stan_verbose = F, HPD_interval = T)
GAMP
GAMP = auxsurvey("Y1~1 + Z1 + Z2 + Z3",  auxiliary = "s(auX_10) + s(logit_true_pi, by = Z1)",
samples = samples, population = population, subset = c("Z1 == 1", "Z1 == 1 & Z2 == 1", "Z1 == 1 & Z2 == 1 & Z3 == 1"), method = "GAMP",
levels = 0.95, nskip = 4000, npost = 4000, nchain = 1, stan_verbose = F, HPD_interval = T)
GAMP
formula = "Y1~1 + Z1 + Z2 + Z3"
auxiliary = "s(auX_10) + s(logit_true_pi, by = Z1)"
subset = c("Z1 == 1", "Z1 == 1 & Z2 == 1", "Z1 == 1 & Z2 == 1 & Z3 == 1")
method = "GAMP"
levels = 0.95
nskip = 4000
npost = 4000
nchain = 1
stan_verbose = F
HPD_interval = T
svyVar = stringr::str_trim(str_split_1(as.character(formula), "~"))
svyVar = svyVar[svyVar != ""][1]
if(!is.null(auxiliary)){
auxiliary = as.character(auxiliary)
auxiliary = stringr::str_remove_all(auxiliary, " ")
auxiliary = paste0(auxiliary, collapse = "+")
if(!str_detect(auxiliary, "^~")){
auxiliary = paste0("~",auxiliary)
}
}
if(length(setdiff(union(all.vars(as.formula(auxiliary)), all.vars(as.formula(formula))), colnames(population))) > 0){
stop(paste0("unidentified variables: ", paste0(setdiff(union(all.vars(as.formula(auxiliary)), all.vars(as.formula(formula))), colnames(population)), collapse = ", "), collapse = ", "))
}
#samples_matrix = model.matrix(as.formula(paste(paste0("~", str_split_i(formula, "~", 2)), paste0(auxiliary, collapse = "+"), sep = "+")), data = samples)
samples = mutate_at(samples, all.vars(as.formula(auxiliary)), as.numeric)
population = mutate_at(population, intersect(all.vars(as.formula(auxiliary)), colnames(population)), as.numeric)
auxiliary_fixed = setdiff(stringr::str_split(stringr::str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T), all.vars(as.formula(auxiliary)))
outcome_formula = paste(formula, paste(auxiliary_fixed, collapse = "+"), sep = "+")
auxiliary_random = intersect(stringr::str_split(stringr::str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T), all.vars(as.formula(auxiliary)))
samples = mutate_at(samples, auxiliary_random, as.factor)
population = mutate_at(population, auxiliary_random, as.factor)
if(length(auxiliary_random) != 0){
outcome_formula = c(outcome_formula, paste0("~", paste0("(1|", auxiliary_random, ")", collapse = "+")))
cat("The formula for the GAMP model is ", paste0(outcome_formula[1], str_replace(outcome_formula[2], "~", "+"), collapse = ""), "\n")
}else{
outcome_formula = c(outcome_formula, NULL)
cat("The formula for the GAMP model is ", outcome_formula[1], "\n")
}
svysmpl = samples
svypopu = population
outcome_formula
BayesFun = "stan_gamm4"
family = gaussian()
invlvls = c(0.95, 05)
weights = NULL
printmod = TRUE
useTrueSample = T
stan_verbose = T
doFigure = FALSE
#print(outcome_formula)
subset = c("T", subset)
subset
fmla <- outcome_formula[1] %>% as.formula()
fmla
#print("start fit model")
if(is.null(weights)){
if(!is.na(outcome_formula[2])){
bayesmod <- get(BayesFun)(fmla, family = family, random = as.formula(outcome_formula[2]), data = svysmpl, iter = nskip + npost, warmup = nskip, chains = nchain, refresh = stan_verbose)
}else{
bayesmod <- get(BayesFun)(fmla, family = family, data = svysmpl, iter = nskip + npost, warmup = nskip, chains = nchain, refresh = stan_verbose)
}
}
printmod
summary(bayesmod) %>% print()
if (doFigure) {
p1 <- pp_check(bayesmod)
p2 <- pp_check(bayesmod, plotfun = 'scatter_avg')
p3 <- pp_check(bayesmod, plotfun = 'stat_2d', stat = c('mean', 'sd'))
p4 <- pp_check(bayesmod, plotfun = "error_binned")
ppcFig <- gridExtra::grid.arrange(p1, p2, p3, ncol = 3)
ppcFig <- gridExtra::grid.arrange(ppcFig, p4, ncol = 1)
ppcFig
}
useTrueSample
mean(population$Y1)
mean(population$Y1[population$Z1 == 1,])
mean(population$Y1[population$Z1 == 1])
data = simulate(N = 3000, discretize = c(3, 10), setting = 1, seed = 123)
population = data$population # get population, 3000 cases
samples = data$samples # get samples, about 600 cases
ipw = 1 / samples$true_pi # get the inverse probability weighting
#print("start fit model")
if(is.null(weights)){
if(!is.na(outcome_formula[2])){
bayesmod <- get(BayesFun)(fmla, family = family, random = as.formula(outcome_formula[2]), data = svysmpl, iter = nskip + npost, warmup = nskip, chains = nchain, refresh = stan_verbose)
}else{
bayesmod <- get(BayesFun)(fmla, family = family, data = svysmpl, iter = nskip + npost, warmup = nskip, chains = nchain, refresh = stan_verbose)
}
}
p1 <- pp_check(bayesmod)
p2 <- pp_check(bayesmod, plotfun = 'scatter_avg')
p3 <- pp_check(bayesmod, plotfun = 'stat_2d', stat = c('mean', 'sd'))
p4 <- pp_check(bayesmod, plotfun = "error_binned")
ppcFig <- gridExtra::grid.arrange(p1, p2, p3, ncol = 3)
ppcFig <- gridExtra::grid.arrange(ppcFig, p4, ncol = 1)
ppcFig
infr = sapply(subset, function(s){
svypopu1 = dplyr::filter(svypopu, eval(parse(text = s)))
svysmpl1 = dplyr::filter(svysmpl, eval(parse(text = s)))
yhats_pop <- posterior_predict(bayesmod, svypopu1, re.form = NA) # npost, non-sample_size
yhats_sam <- posterior_predict(bayesmod, svysmpl1, re.form = NA)
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yobs_tot <- sum(svysmpl1 %>% dplyr::select(str_split_1(outcome_formula[1], "~")[1])) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
tCI = sapply(invlvls, function(level){
#confint(post_est, level = 0.95)
if(shortest_CI){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
return(infr)
}, simplify = F)
shortest_CI = T
infr = sapply(subset, function(s){
svypopu1 = dplyr::filter(svypopu, eval(parse(text = s)))
svysmpl1 = dplyr::filter(svysmpl, eval(parse(text = s)))
yhats_pop <- posterior_predict(bayesmod, svypopu1, re.form = NA) # npost, non-sample_size
yhats_sam <- posterior_predict(bayesmod, svysmpl1, re.form = NA)
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yobs_tot <- sum(svysmpl1 %>% dplyr::select(str_split_1(outcome_formula[1], "~")[1])) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
tCI = sapply(invlvls, function(level){
#confint(post_est, level = 0.95)
if(shortest_CI){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
return(infr)
}, simplify = F)
infr
mean(population$Y1[population$Z1 == 1 & population$Z1 == 2])
mean(population$Y1[population$Z1 == 1 & population$Z2 == 1])
mean(population$Y1[population$Z1 == 1])
svysmpl = samples
svypopu = population
#print("start fit model")
if(is.null(weights)){
if(!is.na(outcome_formula[2])){
bayesmod <- get(BayesFun)(fmla, family = family, random = as.formula(outcome_formula[2]), data = svysmpl, iter = nskip + npost, warmup = nskip, chains = nchain, refresh = stan_verbose)
}else{
bayesmod <- get(BayesFun)(fmla, family = family, data = svysmpl, iter = nskip + npost, warmup = nskip, chains = nchain, refresh = stan_verbose)
}
}
infr = sapply(subset, function(s){
svypopu1 = dplyr::filter(svypopu, eval(parse(text = s)))
svysmpl1 = dplyr::filter(svysmpl, eval(parse(text = s)))
yhats_pop <- posterior_predict(bayesmod, svypopu1, re.form = NA) # npost, non-sample_size
yhats_sam <- posterior_predict(bayesmod, svysmpl1, re.form = NA)
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yobs_tot <- sum(svysmpl1 %>% dplyr::select(str_split_1(outcome_formula[1], "~")[1])) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
tCI = sapply(invlvls, function(level){
#confint(post_est, level = 0.95)
if(shortest_CI){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
return(infr)
}, simplify = F)
infr
mean(population$Y1)
mean(population$Y1[population$Z1 == 1])
mean(population$Y1[population$Z1 == 1 & population$Z2 == 1])
mean(population$Y1[population$Z1 == 1 & population$Z2 == 1 & population$Z3 == 1])
s = "T"
svypopu1 = dplyr::filter(svypopu, eval(parse(text = s)))
svysmpl1 = dplyr::filter(svysmpl, eval(parse(text = s)))
yhats_pop <- posterior_predict(bayesmod, svypopu1, re.form = NA) # npost, non-sample_size
yhats_sam <- posterior_predict(bayesmod, svysmpl1, re.form = NA)
yhats_pop
dim(yhats_pop)
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
dim(yhats_pop_tot)
length(yhats_pop_tot)
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
length(yhats_sam_tot)
yobs_tot <- sum(svysmpl1 %>% dplyr::select(str_split_1(outcome_formula[1], "~")[1])) # a single value
yobs_tot
yhats_sam_tot
(yhats_pop_tot + yobs_tot - yhats_sam_tot)
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
post_est
tCI = sapply(invlvls, function(level){
#confint(post_est, level = 0.95)
if(shortest_CI){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI
tCI = do.call("c", tCI)
tCI
level
invlvls
invlvls = c(0.95, 0.5)
tCI = sapply(invlvls, function(level){
#confint(post_est, level = 0.95)
if(shortest_CI){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI
tCI = do.call("c", tCI)
tCI
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
infr
infr = sapply(subset, function(s){
svypopu1 = dplyr::filter(svypopu, eval(parse(text = s)))
svysmpl1 = dplyr::filter(svysmpl, eval(parse(text = s)))
yhats_pop <- posterior_predict(bayesmod, svypopu1, re.form = NA) # npost, non-sample_size
yhats_sam <- posterior_predict(bayesmod, svysmpl1, re.form = NA)
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yobs_tot <- sum(svysmpl1 %>% dplyr::select(str_split_1(outcome_formula[1], "~")[1])) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
tCI = sapply(invlvls, function(level){
#confint(post_est, level = 0.95)
if(shortest_CI){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
return(infr)
}, simplify = F)
infr
check()
check()
library(devtools)
install_github(https://github.com/zjg540066169/auxsurvey)
install_github("https://github.com/zjg540066169/auxsurvey")
library(AuxSurvey)
check()
library(brms)
?brms
