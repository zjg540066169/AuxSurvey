rownames(est) = "GAMP"
else{
rownames(est) = "Weighted-GAMP"
}
return(est)
})
if(length(GAMP_est) == 1)
return(GAMP_est[[1]])
return(GAMP_est)
}
if(method == "linear"){
if(is.null(nskip)) nskip = 1000
if(is.null(npost)) npost = 1000
if(is.null(nchain)) nchain = 4
samples = mutate_at(samples, all.vars(as.formula(auxiliary)), as.numeric)
population = mutate_at(population, intersect(all.vars(as.formula(auxiliary)), colnames(population)), as.numeric)
auxiliary_fixed = setdiff(stringr::str_split(stringr::str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T), all.vars(as.formula(auxiliary)))
outcome_formula = paste(formula, paste(auxiliary_fixed, collapse = "+"), collapse = "+")
auxiliary_random = intersect(str_split(str_split_i(as.character(auxiliary), "~", 2), "\\+", simplify = T), all.vars(as.formula(auxiliary)))
samples = mutate_at(samples, auxiliary_random, as.factor)
population = mutate_at(population, auxiliary_random, as.factor)
if(length(auxiliary_random) != 0){
outcome_formula = c(outcome_formula, paste0("~", paste0("(1|", auxiliary_random, ")", collapse = "+")))
cat("The formula for the linear model is ", paste0(outcome_formula[1], str_replace(outcome_formula[2], "~", "+"), collapse = ""), "\n")
Linear_est = svyBayesmod(samples, population, outcome_formula, "stan_glmer", family, levels, weights, nskip, npost, nchain, printmod = T, doFigure = F, useTrueSample = T, stan_verbose = stan_verbose, shortest_CI = HPD_interval)
}else{
outcome_formula = c(outcome_formula, NULL)
cat("The formula for the linear model is ", outcome_formula, "\n")
Linear_est = svyBayesmod(samples, population, outcome_formula, "stan_glm", subset, family, levels, weights, nskip, npost, nchain, printmod = T, doFigure = F, useTrueSample = T, stan_verbose = stan_verbose, shortest_CI = HPD_interval)
}
Linear_est = lapply(Linear_est, function(est){
if(is.null(weights))
rownames(est) = "linear"
else{
rownames(est) = "Weighted-linear"
}
return(est)
})
if(length(Linear_est) == 1)
return(Linear_est[[1]])
#outcome_formula = paste(formula, paste0(str_remove_all(auxiliary, "~"), collapse = "+"), paste0("(1|", auxiliary_random, ")", collapse = "+"),  sep = "+")
return(Linear_est)
}
}
MRP_1 = auxsurvey("y~female + enlist",  auxiliary = "race_c + agecat + marital_c + X1cut", samples = smpl, population = appended_pop, subset = NULL, family = binomial(), method = "MRP", levels = 0.95, npost = 1000, nskip = 1000, nchain = 1)
devtools::check()
load("/Users/zoujungang/Downloads/smpl.RData")
load("/Users/zoujungang/Downloads/appended_pop.RData")
remove.packages("AuxSurvey")
devtools::install_github("https://github.com/zjg540066169/AuxSurvey")
library(AuxSurvey)
MRP_1 = auxsurvey("y~female + enlist",  auxiliary = "race_c + agecat + marital_c + X1cut", samples = smpl, population = appended_pop, subset = NULL, family = binomial(), method = "MRP", levels = 0.95, HPD_interval = T, npost = 4000, nskip = 4000, nchain = 2)
MRP_1
View(smpl)
MRP_1 = auxsurvey("y~female + enlist",  auxiliary = "race_c + agecat + marital_c + X1cut", samples = smpl, population = appended_pop, subset = "female == 0", family = binomial(), method = "MRP", levels = 0.95, HPD_interval = T, npost = 200, nskip = 200, nchain = 1)
MRP_1
devtools::check()
?survey::svydesign
check()
devtools::check()
devtools::check()
library(gtools)
library(tidyverse)
library(mgcv)
library(rstanarm)
#' @return simulated dataset
#' @export
#'
#' @import stats
#' @import gtools
#' @import tidyverse
#' @import mgcv
#' @import dplyr
#' @import stringr
#'
simulate = function(N = 3000, discretize =c(3, 5, 10), setting = c(1,2,3), seed = NULL){
if(!is.null(seed))
set.seed(seed)
Z = sapply(c(0.7, 0.5, 0.4), function(p){
return(rbinom(N, 1, p))
})
X = rnorm(N)
W = rnorm(N)
auX = sapply(discretize, function(q) gtools::quantcut(X, q = q, labels = FALSE))
colnames(auX) = paste0("auX_", discretize)
auW = sapply(discretize, function(q) gtools::quantcut(W, q = q, labels = FALSE))
colnames(auW) = paste0("auW_", discretize)
if(setting == 1){
pi = rstanarm::invlogit(- 1.25 - Z[,1] + 1.25*Z[,2] - 0.75*Z[,3] + 0.75*X - 0.10*X^2)
Y1 = rnorm(N, 15 + 2.5*Z[,1] - Z[,2] + Z[,3] - 2*X + 3.75*X^2, 3)
Y2 = rbinom(N, 1, rstanarm::invlogit(-2.5 + 0.75*Z[,1] - 2.5*Z[,2] + 1.5*Z[,3] - 0.25*X + 1.5*X^2))
}
if(setting == 2){
pi = rstanarm::invlogit(- 1.25 - Z[,1] + 1.25*Z[,2] - 0.75*Z[,3] + 0.75*W - 0.10*W^2)
Y1 = rnorm(N, 15 + 2.5*Z[,1] - Z[,2] + Z[,3] - 2*X + 3.75*X^2, 3)
Y2 = rbinom(N, 1, rstanarm::invlogit(-2.5 + 0.75*Z[,1] - 2.5*Z[,2] + 1.5*Z[,3] - 0.25*X + 1.5*X^2))
}
if(setting == 3){
pi = rstanarm::invlogit(-0.9 - 0.5 * Z[,1] + 0.75 * Z[,2] - Z[,3] + 0.5 * X - 0.05 * X^2 + 0.5 * Z[,1] * X - 0.75 * Z[,1] * X^2)
Y1 = rnorm(N, 15 + 2.5 * Z[,1] - Z[,2] + Z[,3] - 2 * X + X^2 + Z[,1] * X - 2.5 * Z[,1] * X^2, 2)
Y2 = rbinom(N, 1, rstanarm::invlogit(-1.75 + 0.75 * Z[,1] - 1.5 * Z[,2] + 1.5 * Z[,3] - 1.5 * X + X^2 + Z[,1] * X - 2.5 * Z[,1] * X^2))
}
population = data.frame(
id = seq(1, N),
Z = Z,
X = X,
W = W,
auX = auX,
auW = auW,
Y1 = Y1,
Y2 = Y2,
true_pi = pi,
logit_true_pi = gtools::logit(pi)
)
U = runif(N)
population$inclusion = ifelse(pi > U, T, F)
samples = population[population$inclusion == T,]
colnames(population) = c("id", "Z1", "Z2", "Z3", "X", "W", colnames(auX), colnames(auW), "Y1", "Y2", "true_pi", "logit_true_pi", "inclusion")
colnames(samples) = c("id", "Z1", "Z2", "Z3", "X", "W", colnames(auX), colnames(auW), "Y1", "Y2", "true_pi", "logit_true_pi", "inclusion")
ps_model = BART::pbart(as.matrix(population[, c("Z1", "Z2", "Z3", "X")]), population$inclusion, ntree=50, keepevery= 1, ndpost = 100)
population$estimated_pi = predict(ps_model, as.matrix(population[, c("Z1", "Z2", "Z3", "X")]))$prob.test.mean
samples$estimated_pi = predict(ps_model, as.matrix(samples[, c("Z1", "Z2", "Z3", "X")]))$prob.test.mean
population$logit_estimated_pi = logit(population$estimated_pi)
samples$logit_estimated_pi = logit(samples$estimated_pi)
ps_model_with_W <- BART::pbart(as.matrix(population[, c("Z1", "Z2", "Z3", "X", "W")]), population$inclusion, ntree=50, keepevery= 1, ndpost = 100)
population$estimated_pi_with_W = predict(ps_model_with_W, as.matrix(population[, c("Z1", "Z2", "Z3", "X", "W")]))$prob.test.mean
samples$estimated_pi_with_W = predict(ps_model_with_W, as.matrix(samples[, c("Z1", "Z2", "Z3", "X", "W")]))$prob.test.mean
population$logit_estimated_pi_with_W = logit(population$estimated_pi_with_W)
samples$logit_estimated_pi_with_W = logit(samples$estimated_pi_with_W)
samples$inclusion = NULL
population$inclusion = NULL
return(list(population = as_tibble(population), samples = as_tibble(samples)))
}
simulate(N = 3000, discretize =c(3, 5, 10), setting = c(1,2,3), seed = NULL)
simulate(N = 3000, discretize =c(3, 5, 10), setting = 1, seed = NULL)
data = simulate(N = 3000, discretize =c(3, 5, 10), setting = 1, seed = NULL)
population = data$population # get population, 3000 cases
samples = data$samples # get samples, about 600 cases
nskip = 1000
npost = 1000
nchain = 1
formula = "Y1 ~ Z1 + Z2 + Z3 + auX_5"
covariates = str_trim(str_split(str_split_i(as.character(formula), "~", 2), "\\+", simplify = T))
covariates = setdiff(covariates, svyVar)
svyVar = stringr::str_trim(str_split_1(as.character(formula), "~"))
svyVar = svyVar[svyVar != ""][1]
covariates = str_trim(str_split(str_split_i(as.character(formula), "~", 2), "\\+", simplify = T))
covariates = setdiff(covariates, svyVar)
if("." %in% covariates){
covariates = setdiff(names(samples), svyVar)
}
for(i in covariates){
if(is.character(samples[,i])){
samples[,i] = as.factor(samples[,i])
population[,i] = as.factor(population[,i])
}
}
family = gaussian()
family
X_train = as.matrix(samples[, covariates])
y_train = samples[, svyVar]
model = BART::wbart(X_train, y_train, ndpost = npost, nskip = nskip)
as.matrix(samples[, covariates])
samples[, svyVar]
y_train = pull(samples, svyVar)
model = BART::wbart(X_train, y_train, ndpost = npost, nskip = nskip)
model
subset = c("T", subset)
subset = c("Z1 == 1", "Z1==1 & Z2==1")
subset = c("T", subset)
s = subset[1]
svypopu1 = dplyr::filter(population, eval(parse(text = s)))
svysmpl1 = dplyr::filter(samples, eval(parse(text = s)))
yhats_pop <- predict(model, svypopu1) # npost, non-sample_size
svypopu1 = as.matrix(dplyr::filter(population, eval(parse(text = s)))[, covariates])
svysmpl1 = as.matrix(dplyr::filter(samples, eval(parse(text = s))))[, covariates])
svysmpl1 = as.matrix(dplyr::filter(samples, eval(parse(text = s)))[, covariates])
yhats_pop <- predict(model, svypopu1) # npost, non-sample_size
yhats_sam <- predict(model, svysmpl1)
suppressWarnings(yhats_pop <- predict(model, svypopu1)) # npost, non-sample_size
suppressWarnings(yhats_sam <- predict(model, svysmpl1))
suppressMessages(yhats_pop <- predict(model, svypopu1)) # npost, non-sample_size
suppressMessages(yhats_sam <- predict(model, svysmpl1))
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
suppressMessages(yhats_pop <- predict(model, svypopu1) # npost, non-sample_size
, yhats_sam <- predict(model, svysmpl1))
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
pull(as.matrix(dplyr::filter(samples, eval(parse(text = s)))[, covariates]), svyVar)
pull(dplyr::filter(samples, eval(parse(text = s))), svyVar)
yobs_tot <- sum(pull(dplyr::filter(samples, eval(parse(text = s))), svyVar)) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
post_est
yobs_tot
yhats_sam_tot
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
infr = sapply(subset, function(s){
svypopu1 = as.matrix(dplyr::filter(population, eval(parse(text = s)))[, covariates])
svysmpl1 = as.matrix(dplyr::filter(samples, eval(parse(text = s)))[, covariates])
suppressMessages(yhats_pop <- predict(model, svypopu1)) # npost, non-sample_size
suppressMessages(yhats_sam <- predict(model, svysmpl1))
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yobs_tot <- sum(pull(dplyr::filter(samples, eval(parse(text = s))), svyVar)) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
tCI = sapply(invlvls, function(level){
#confint(post_est, level = 0.95)
if(shortest_CI){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
return(infr)
}, simplify = F)
levels = c(0.95, 0.8, 0.5)
infr = sapply(subset, function(s){
svypopu1 = as.matrix(dplyr::filter(population, eval(parse(text = s)))[, covariates])
svysmpl1 = as.matrix(dplyr::filter(samples, eval(parse(text = s)))[, covariates])
suppressMessages(yhats_pop <- predict(model, svypopu1)) # npost, non-sample_size
suppressMessages(yhats_sam <- predict(model, svysmpl1))
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yobs_tot <- sum(pull(dplyr::filter(samples, eval(parse(text = s))), svyVar)) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
tCI = sapply(levels, function(level){
#confint(post_est, level = 0.95)
if(shortest_CI){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
return(infr)
}, simplify = F)
infr = sapply(subset, function(s){
svypopu1 = as.matrix(dplyr::filter(population, eval(parse(text = s)))[, covariates])
svysmpl1 = as.matrix(dplyr::filter(samples, eval(parse(text = s)))[, covariates])
suppressMessages(yhats_pop <- predict(model, svypopu1)) # npost, non-sample_size
suppressMessages(yhats_sam <- predict(model, svysmpl1))
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yobs_tot <- sum(pull(dplyr::filter(samples, eval(parse(text = s))), svyVar)) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
tCI = sapply(levels, function(level){
#confint(post_est, level = 0.95)
if(HPD_interval){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
return(infr)
}, simplify = F)
HPD_interval = T
infr = sapply(subset, function(s){
svypopu1 = as.matrix(dplyr::filter(population, eval(parse(text = s)))[, covariates])
svysmpl1 = as.matrix(dplyr::filter(samples, eval(parse(text = s)))[, covariates])
suppressMessages(yhats_pop <- predict(model, svypopu1)) # npost, non-sample_size
suppressMessages(yhats_sam <- predict(model, svysmpl1))
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yobs_tot <- sum(pull(dplyr::filter(samples, eval(parse(text = s))), svyVar)) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
tCI = sapply(levels, function(level){
#confint(post_est, level = 0.95)
if(HPD_interval){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
return(infr)
}, simplify = F)
infr
infr
BART_est =  lapply(infr, function(est){
if(is.null(weights))
rownames(est) = "BART"
else{
rownames(est) = "Weighted-BART"
}
return(est)
})
if(length(BART_est) == 1)
return(BART[[1]])
return(BART)
if(method == "BART"){
if(is.null(nskip)) nskip = 1000
if(is.null(npost)) npost = 1000
if(is.null(nchain)) nchain = 1
covariates = str_trim(str_split(str_split_i(as.character(formula), "~", 2), "\\+", simplify = T))
covariates = setdiff(covariates, svyVar)
if("." %in% covariates){
covariates = setdiff(names(samples), svyVar)
}
for(i in covariates){
if(is.character(samples[,i])){
samples[,i] = as.factor(samples[,i])
population[,i] = as.factor(population[,i])
}
}
if(family$family == "binomial"){
}
if(family$family == "gaussian"){
X_train = as.matrix(samples[, covariates])
y_train = pull(samples, svyVar)
model = BART::wbart(X_train, y_train, ndpost = npost, nskip = nskip)
}
subset = c("T", subset)
infr = sapply(subset, function(s){
svypopu1 = as.matrix(dplyr::filter(population, eval(parse(text = s)))[, covariates])
svysmpl1 = as.matrix(dplyr::filter(samples, eval(parse(text = s)))[, covariates])
suppressMessages(yhats_pop <- predict(model, svypopu1)) # npost, non-sample_size
suppressMessages(yhats_sam <- predict(model, svysmpl1))
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yobs_tot <- sum(pull(dplyr::filter(samples, eval(parse(text = s))), svyVar)) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
tCI = sapply(levels, function(level){
#confint(post_est, level = 0.95)
if(HPD_interval){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
return(infr)
}, simplify = F)
names(infr)[1] = "All"
BART_est =  lapply(infr, function(est){
if(is.null(weights))
rownames(est) = "BART"
else{
rownames(est) = "Weighted-BART"
}
return(est)
})
if(length(BART_est) == 1)
return(BART[[1]])
return(BART)
}
svyVar = "Y2"
X_train = as.matrix(samples[, covariates])
y_train = pull(samples, svyVar)
model = BART::pbart(X_train, y_train, ndpost = npost, nskip = nskip)
?BART::wbart
?BART::pbart
s
svypopu1 = as.matrix(dplyr::filter(population, eval(parse(text = s)))[, covariates])
svysmpl1 = as.matrix(dplyr::filter(samples, eval(parse(text = s)))[, covariates])
suppressMessages(yhats_pop <- predict(model, svypopu1)) # npost, non-sample_size
invisible(capture.output( yhats_pop <- predict(model, svypopu1))) # npost, non-sample_size
invisible(capture.output( yhats_sam <- predict(model, svysmpl1)))
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yhats_pop
yhats_pop <- predict(model, svypopu1)
yhats_pop
yhats_pop$yhat.test
dim(yhats_pop$yhat.test)
yhats_pop$yhat.test[,1,]
yhats_pop$yhat.test[1,1]
yhats_pop$prob.test.mean
yhats_pop$prob.test
yhats_pop$prob.test
yhats_pop$prob.test[1,1]
yhats_pop$prob.test[1,2]
?map
apply(yhats_pop$prob.test, c(1, 2), function(x) rbinom(1, size = 1, prob = x))
yhats_pop = apply(yhats_pop$prob.test, c(1, 2), function(x) rbinom(1, size = 1, prob = x))
yhats_pop
dim( yhats_pop)
yhats_pop[1,1]
yhats_pop[1,2]
yhats_pop[1,3]
yhats_pop[1,4]
yhats_pop[1,5]
yhats_pop[1,6]
summary(yhats_pop)
summary(yhats_pop[1,])
summary(yhats_pop[2,])
yhats_sam = apply(yhats_sam$prob.test, c(1, 2), function(x) rbinom(1, size = 1, prob = x))
yhats_sam
svyVar
infr = sapply(subset, function(s){
svypopu1 = as.matrix(dplyr::filter(population, eval(parse(text = s)))[, covariates])
svysmpl1 = as.matrix(dplyr::filter(samples, eval(parse(text = s)))[, covariates])
invisible(capture.output( yhats_pop <- predict(model, svypopu1))) # npost, non-sample_size
invisible(capture.output( yhats_sam <- predict(model, svysmpl1)))
if(family$family == "binomial"){
yhats_pop = apply(yhats_pop$prob.test, c(1, 2), function(x) rbinom(1, size = 1, prob = x))
yhats_sam = apply(yhats_sam$prob.test, c(1, 2), function(x) rbinom(1, size = 1, prob = x))
}
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yobs_tot <- sum(pull(dplyr::filter(samples, eval(parse(text = s))), svyVar)) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
tCI = sapply(levels, function(level){
#confint(post_est, level = 0.95)
if(HPD_interval){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
return(infr)
}, simplify = F)
X_train = as.matrix(samples[, covariates])
y_train = pull(samples, svyVar)
model = BART::pbart(X_train, y_train, ndpost = npost, nskip = nskip)
subset
s = subset[1]
svypopu1 = as.matrix(dplyr::filter(population, eval(parse(text = s)))[, covariates])
svysmpl1 = as.matrix(dplyr::filter(samples, eval(parse(text = s)))[, covariates])
invisible(capture.output( yhats_pop <- predict(model, svypopu1))) # npost, non-sample_size
invisible(capture.output( yhats_sam <- predict(model, svysmpl1)))
if(family$family == "binomial"){
yhats_pop = apply(yhats_pop$prob.test, c(1, 2), function(x) rbinom(1, size = 1, prob = x))
yhats_sam = apply(yhats_sam$prob.test, c(1, 2), function(x) rbinom(1, size = 1, prob = x))
}
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_pop
family
family = binomial()
if(family$family == "binomial"){
X_train = as.matrix(samples[, covariates])
y_train = pull(samples, svyVar)
model = BART::pbart(X_train, y_train, ndpost = npost, nskip = nskip)
}
infr = sapply(subset, function(s){
svypopu1 = as.matrix(dplyr::filter(population, eval(parse(text = s)))[, covariates])
svysmpl1 = as.matrix(dplyr::filter(samples, eval(parse(text = s)))[, covariates])
invisible(capture.output( yhats_pop <- predict(model, svypopu1))) # npost, non-sample_size
invisible(capture.output( yhats_sam <- predict(model, svysmpl1)))
if(family$family == "binomial"){
yhats_pop = apply(yhats_pop$prob.test, c(1, 2), function(x) rbinom(1, size = 1, prob = x))
yhats_sam = apply(yhats_sam$prob.test, c(1, 2), function(x) rbinom(1, size = 1, prob = x))
}
yhats_pop_tot <- yhats_pop %>% apply(1, sum) # npost * 1
yhats_sam_tot <- yhats_sam %>% apply(1, sum) # npost * 1
yobs_tot <- sum(pull(dplyr::filter(samples, eval(parse(text = s))), svyVar)) # a single value
post_est = (yhats_pop_tot + yobs_tot - yhats_sam_tot) / nrow(svypopu1) #npost
tCI = sapply(levels, function(level){
#confint(post_est, level = 0.95)
if(HPD_interval){
class(post_est) <- 'mcmc'
ci = coda::HPDinterval(post_est, prob = level, names = T)
names(ci) = paste(((1 - level)/2 * c(1, -1) + c(0, 1)) * 100, "%")
}else{
ci = ((1 - level)/2 * c(1, -1) + c(0, 1))
ci = quantile(post_est, probs = ci, names = T)
names(ci) = str_replace(names(ci), "%", " %")
}
ci
}, simplify = F)
tCI = do.call("c", tCI)
infr <- rbind(c(post_mean_est = mean(post_est), post_median_est = median(post_est), se = sd(post_est), tCI, sample_size = nrow(svysmpl1), population_size = nrow(svypopu1)))
return(infr)
}, simplify = F)
infr
names(infr)[1] = "All"
?pbart
BART_est =  lapply(infr, function(est){
rownames(est) = "BART"
return(est)
})
BART_est
devtools::check()
devtools::check()
